{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO+5JwDZt4MIlRdg3RU8JDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananya12k/Car_Detection_in_Low_Visibility/blob/main/DAWN_YOLOv8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMoTX1SFgt5L",
        "outputId": "1b1ce1c2-7944-4769-8bce-f013b8fc2d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.81-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.5-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.81-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m869.4/869.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.5-py3-none-any.whl (25 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.81 ultralytics-thop-2.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME=os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHs9CFWng3gR",
        "outputId": "48a7da9e-b026-471c-8c6f-6de538f0454e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n"
      ],
      "metadata": {
        "id": "a0zFVFkjg5WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "xPA7wUZtg6yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGBoE6-wg8an",
        "outputId": "a0799c99-c044-4645-ade6-6d8747328923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"GULd2XwyTBxpwq78xzZk\")\n",
        "project = rf.workspace(\"myworkspace-qfjqk\").project(\"car_detection-hpsgk\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8-obb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqVwU5Qeg-fs",
        "outputId": "d15cfcc1-7661-4a28-cc34-07f845e3b2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.42-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.7.4)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Downloading roboflow-1.1.42-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, requests-toolbelt, roboflow\n",
            "Successfully installed filetype-1.2.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.42\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Car_detection-1 to yolov8-obb:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171122/171122 [00:04<00:00, 39089.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Car_detection-1 in yolov8-obb:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4810/4810 [00:00<00:00, 4953.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6l9B0gi3hABv",
        "outputId": "96f97b4c-ba42-4480-8f28-0c2b25e0631a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/datasets'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov8n.pt data={dataset.location}/data.yaml epochs=30 imgsz=800"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWhDeksZhYP4",
        "outputId": "210ae70e-0a11-49c3-f9b6-9b4e7e46642f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.25M/6.25M [00:00<00:00, 121MB/s]\n",
            "Ultralytics YOLOv8.2.81 ğŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/datasets/Car_detection-1/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=800, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 18.2MB/s]\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/Car_detection-1/train/labels... 2100 images, 0 backgrounds, 0 corrupt: 100% 2100/2100 [00:01<00:00, 1297.68it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/Car_detection-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Car_detection-1/valid/labels... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<00:00, 895.56it/s] \n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/Car_detection-1/valid/labels.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 800 train, 800 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30      4.03G       1.52       2.44      1.325         52        800: 100% 132/132 [01:27<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:07<00:00,  1.00s/it]\n",
            "                   all        199       1562      0.634      0.264      0.257      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30      4.69G      1.439      1.649      1.297         24        800: 100% 132/132 [01:06<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.56it/s]\n",
            "                   all        199       1562      0.757      0.239      0.234      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30      4.79G      1.389      1.481      1.271         11        800: 100% 132/132 [01:06<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.50it/s]\n",
            "                   all        199       1562      0.581      0.247      0.258      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30      4.34G      1.395      1.431       1.27         29        800: 100% 132/132 [01:09<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.66it/s]\n",
            "                   all        199       1562      0.648      0.246      0.302      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30      4.74G      1.354      1.282      1.229         75        800: 100% 132/132 [01:06<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.99it/s]\n",
            "                   all        199       1562      0.625      0.211      0.236      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30      4.15G      1.333      1.224      1.227         48        800: 100% 132/132 [01:05<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.56it/s]\n",
            "                   all        199       1562      0.517      0.445      0.388      0.209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30      3.97G      1.325      1.171      1.223         41        800: 100% 132/132 [01:04<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.71it/s]\n",
            "                   all        199       1562      0.606      0.384      0.406      0.228\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30      4.29G      1.297      1.145      1.212         33        800: 100% 132/132 [01:06<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.50it/s]\n",
            "                   all        199       1562       0.53      0.413      0.379      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30      4.48G      1.282      1.101      1.196         57        800: 100% 132/132 [01:05<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.51it/s]\n",
            "                   all        199       1562       0.79      0.332      0.426      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30      4.62G      1.259       1.07      1.185         43        800: 100% 132/132 [01:06<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.71it/s]\n",
            "                   all        199       1562      0.694       0.44      0.477      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30       4.1G      1.247       1.05      1.187         13        800: 100% 132/132 [01:06<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.28it/s]\n",
            "                   all        199       1562      0.418      0.417      0.442      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30       4.5G      1.237      1.022      1.178         73        800: 100% 132/132 [01:05<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.53it/s]\n",
            "                   all        199       1562      0.685      0.336      0.443      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30      4.46G       1.23      1.018      1.173         55        800: 100% 132/132 [01:04<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.64it/s]\n",
            "                   all        199       1562      0.458      0.448      0.451      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30      4.07G      1.213     0.9802      1.166         29        800: 100% 132/132 [01:06<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.61it/s]\n",
            "                   all        199       1562      0.563      0.439      0.447       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30      4.49G      1.221     0.9764      1.164         50        800: 100% 132/132 [01:06<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.56it/s]\n",
            "                   all        199       1562      0.672      0.436      0.476      0.289\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30      4.87G      1.206     0.9661      1.163         12        800: 100% 132/132 [01:06<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.48it/s]\n",
            "                   all        199       1562      0.699       0.46      0.509      0.299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30      4.18G      1.193      0.926      1.149         46        800: 100% 132/132 [01:06<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.56it/s]\n",
            "                   all        199       1562      0.646      0.469      0.515      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30      4.33G      1.188     0.9229      1.147         32        800: 100% 132/132 [01:05<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.65it/s]\n",
            "                   all        199       1562      0.444      0.478      0.489      0.289\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30      5.04G      1.155      0.893      1.138         59        800: 100% 132/132 [01:06<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.42it/s]\n",
            "                   all        199       1562      0.419      0.579      0.502      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30      3.66G      1.146     0.8747      1.126         45        800: 100% 132/132 [01:07<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  2.19it/s]\n",
            "                   all        199       1562      0.472      0.527      0.516        0.3\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30      4.02G       1.15     0.8199      1.139         49        800: 100% 132/132 [01:01<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:04<00:00,  1.54it/s]\n",
            "                   all        199       1562       0.66      0.498      0.494      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30       4.5G      1.109     0.7754      1.116         29        800: 100% 132/132 [00:56<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.62it/s]\n",
            "                   all        199       1562      0.509      0.539      0.523      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30      3.98G      1.106     0.7659      1.112         62        800: 100% 132/132 [00:57<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:03<00:00,  1.88it/s]\n",
            "                   all        199       1562      0.555      0.486      0.522      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30      3.58G      1.092     0.7487      1.103         15        800: 100% 132/132 [00:56<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.70it/s]\n",
            "                   all        199       1562      0.521      0.541      0.519      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30      3.93G      1.077     0.7295       1.09         16        800: 100% 132/132 [01:00<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.34it/s]\n",
            "                   all        199       1562      0.541      0.479      0.516       0.32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30      4.02G      1.062     0.7054      1.081         12        800: 100% 132/132 [00:56<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.52it/s]\n",
            "                   all        199       1562       0.55      0.517      0.546      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30      3.58G      1.055     0.7008      1.084         16        800: 100% 132/132 [01:00<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.82it/s]\n",
            "                   all        199       1562      0.771      0.465      0.546      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30      3.96G      1.044     0.6886      1.078         33        800: 100% 132/132 [00:56<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.49it/s]\n",
            "                   all        199       1562      0.567      0.471      0.542      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30      4.25G      1.032      0.673      1.074         38        800: 100% 132/132 [00:58<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.76it/s]\n",
            "                   all        199       1562      0.586      0.514      0.566      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30      4.35G      1.026     0.6644      1.071         22        800: 100% 132/132 [00:56<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:02<00:00,  2.61it/s]\n",
            "                   all        199       1562      0.591      0.509      0.581      0.374\n",
            "\n",
            "30 epochs completed in 0.574 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.81 ğŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 7/7 [00:10<00:00,  1.47s/it]\n",
            "                   all        199       1562       0.59      0.509      0.578      0.371\n",
            "                     1         26         55      0.751      0.509      0.617      0.357\n",
            "                     2          3          5      0.143     0.0573       0.18       0.12\n",
            "                     3        197       1335      0.864      0.819      0.893      0.601\n",
            "                     4          7          9      0.644      0.667      0.608      0.335\n",
            "                     6         21         30      0.433      0.433       0.53       0.44\n",
            "                     8         60        128      0.707       0.57      0.638      0.375\n",
            "Speed: 0.6ms preprocess, 3.8ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect \\\n",
        "mode=val \\\n",
        "model={HOME}/datasets/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGZ_KfYyhZ9x",
        "outputId": "e5a56c38-01fa-4342-d0c2-8c285a73537f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.81 ğŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Car_detection-1/valid/labels.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 13/13 [00:09<00:00,  1.34it/s]\n",
            "                   all        199       1562       0.59      0.509      0.581      0.375\n",
            "                     1         26         55       0.75      0.509      0.617       0.36\n",
            "                     2          3          5      0.147     0.0588       0.18       0.12\n",
            "                     3        197       1335      0.862      0.816      0.892      0.601\n",
            "                     4          7          9      0.643      0.667      0.626       0.35\n",
            "                     6         21         30      0.435      0.433      0.531      0.447\n",
            "                     8         60        128      0.703       0.57      0.639      0.374\n",
            "Speed: 6.7ms preprocess, 6.7ms inference, 0.1ms loss, 6.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect \\\n",
        "mode=predict \\\n",
        "model={HOME}/datasets/runs/detect/train/weights/best.pt \\\n",
        "conf=0.1 \\\n",
        "iou=0.8 \\\n",
        "imgsz=800 \\\n",
        "line_width=3 \\\n",
        "show_labels=True \\\n",
        "show_conf=True \\\n",
        "source={dataset.location}/test/images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R_TtUvphdmj",
        "outputId": "99a49806-d256-41d1-89bf-c45f484a2d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.81 ğŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/100 /content/datasets/Car_detection-1/test/images/dusttornado-006_jpg.rf.ee18e939e49ce66f7acce6daf25423c4.jpg: 800x800 1 1, 3 3s, 21.2ms\n",
            "image 2/100 /content/datasets/Car_detection-1/test/images/dusttornado-017_jpg.rf.49a29f8d008902b045e4175ee6acac4e.jpg: 800x800 9 1s, 4 3s, 1 6, 2 8s, 10.1ms\n",
            "image 3/100 /content/datasets/Car_detection-1/test/images/dusttornado-033_jpg.rf.94457bc9981873f3423a50aa55f28116.jpg: 800x800 7 3s, 3 8s, 11.0ms\n",
            "image 4/100 /content/datasets/Car_detection-1/test/images/foggy-009_jpg.rf.1616ba7dd0e36c3445e74a76387388a7.jpg: 800x800 1 1, 4 3s, 2 4s, 10.8ms\n",
            "image 5/100 /content/datasets/Car_detection-1/test/images/foggy-031_jpg.rf.b22c5705745e4cffcec8d6828bc67493.jpg: 800x800 3 3s, 10.0ms\n",
            "image 6/100 /content/datasets/Car_detection-1/test/images/foggy-044_jpg.rf.099d61e03dc6fa9f321da8e20274b48e.jpg: 800x800 4 3s, 2 8s, 11.1ms\n",
            "image 7/100 /content/datasets/Car_detection-1/test/images/foggy-057_jpg.rf.63b33de8001849a190e6264823e0637a.jpg: 800x800 2 3s, 1 6, 2 8s, 11.3ms\n",
            "image 8/100 /content/datasets/Car_detection-1/test/images/foggy-069_jpg.rf.f633ae9562b61bb0282fd508b395013e.jpg: 800x800 5 3s, 2 8s, 10.2ms\n",
            "image 9/100 /content/datasets/Car_detection-1/test/images/foggy-072_jpg.rf.f42dff7773041954d7a5245357be759d.jpg: 800x800 1 3, 1 6, 2 8s, 10.0ms\n",
            "image 10/100 /content/datasets/Car_detection-1/test/images/foggy-106_jpg.rf.33218da224f208546d5cb268219e61d6.jpg: 800x800 2 3s, 10.8ms\n",
            "image 11/100 /content/datasets/Car_detection-1/test/images/foggy-112_jpg.rf.a3548c1f36bbeb9697ad316d6f168738.jpg: 800x800 37 3s, 1 4, 10.3ms\n",
            "image 12/100 /content/datasets/Car_detection-1/test/images/haze-004_jpg.rf.f8e2ba448820ce1fd21216b90be90db7.jpg: 800x800 1 3, 11.2ms\n",
            "image 13/100 /content/datasets/Car_detection-1/test/images/haze-012_jpg.rf.5a5a05c0047c31012f6e50906a5d1831.jpg: 800x800 (no detections), 10.7ms\n",
            "image 14/100 /content/datasets/Car_detection-1/test/images/haze-019_jpg.rf.f12a0156d36124f0aac9760a64213f3b.jpg: 800x800 9 1s, 10 3s, 1 4, 10.6ms\n",
            "image 15/100 /content/datasets/Car_detection-1/test/images/haze-022_jpg.rf.99be0a7aad4099863cfd64f3eb542a59.jpg: 800x800 8 3s, 1 8, 13.7ms\n",
            "image 16/100 /content/datasets/Car_detection-1/test/images/haze-075_jpg.rf.2f9c87b368258e660dd27c7b6d6e336e.jpg: 800x800 4 3s, 11.2ms\n",
            "image 17/100 /content/datasets/Car_detection-1/test/images/haze-080_jpg.rf.8f98cc039e3c124dab30c933d9fc14b1.jpg: 800x800 4 3s, 11.0ms\n",
            "image 18/100 /content/datasets/Car_detection-1/test/images/haze-106_jpg.rf.5203bfa1358a6002af4dd24f729418c7.jpg: 800x800 54 3s, 11.5ms\n",
            "image 19/100 /content/datasets/Car_detection-1/test/images/mist-019_jpg.rf.613c1c49f102a51a13285c86196d52af.jpg: 800x800 7 3s, 10.1ms\n",
            "image 20/100 /content/datasets/Car_detection-1/test/images/mist-023_jpg.rf.57bc6520c3ee8380045807c03ab90d5d.jpg: 800x800 28 3s, 10.1ms\n",
            "image 21/100 /content/datasets/Car_detection-1/test/images/mist-039_jpg.rf.5b8f825508970258e9b7880f00858fd6.jpg: 800x800 2 3s, 11.2ms\n",
            "image 22/100 /content/datasets/Car_detection-1/test/images/mist-059_jpg.rf.a485530df5e287b48abfb27bb566dead.jpg: 800x800 9 3s, 10.1ms\n",
            "image 23/100 /content/datasets/Car_detection-1/test/images/mist-067_jpg.rf.a767998025ffb7cad53dac494688e2b0.jpg: 800x800 1 8, 11.1ms\n",
            "image 24/100 /content/datasets/Car_detection-1/test/images/mist-120_jpg.rf.3c044fa4684a6b67cd2ba4d89c1d71bf.jpg: 800x800 18 3s, 3 8s, 12.8ms\n",
            "image 25/100 /content/datasets/Car_detection-1/test/images/mist-133_jpg.rf.b9569463b50af08fefacffe00741f858.jpg: 800x800 1 3, 11.0ms\n",
            "image 26/100 /content/datasets/Car_detection-1/test/images/mist-137_jpg.rf.0b43987df80c2a2afe154c1393dc3128.jpg: 800x800 3 3s, 10.6ms\n",
            "image 27/100 /content/datasets/Car_detection-1/test/images/mist-148_jpg.rf.ccc445e613f84539256105fd1167d1c6.jpg: 800x800 5 3s, 1 6, 2 8s, 10.2ms\n",
            "image 28/100 /content/datasets/Car_detection-1/test/images/rain_storm-002_jpg.rf.510b3c54dcac1760456305c65874df84.jpg: 800x800 11 1s, 2 3s, 5 4s, 11.1ms\n",
            "image 29/100 /content/datasets/Car_detection-1/test/images/rain_storm-006_jpg.rf.8ce60ad77dee99a1bd4ea05aeb731ecd.jpg: 800x800 3 1s, 8 3s, 10.0ms\n",
            "image 30/100 /content/datasets/Car_detection-1/test/images/rain_storm-015_jpg.rf.22db21de52ebd09ee7460deab42f52be.jpg: 800x800 16 3s, 11.2ms\n",
            "image 31/100 /content/datasets/Car_detection-1/test/images/rain_storm-022_jpg.rf.b5b5afa7dd33d0e6c5f3bb82dc4b00a5.jpg: 800x800 12 3s, 1 8, 10.0ms\n",
            "image 32/100 /content/datasets/Car_detection-1/test/images/rain_storm-078_jpg.rf.64e7b2a3b452809cbc89780b931730c2.jpg: 800x800 36 3s, 1 6, 4 8s, 10.0ms\n",
            "image 33/100 /content/datasets/Car_detection-1/test/images/rain_storm-146_jpg.rf.876196d59a9a7138d5698c4eebb4a12d.jpg: 800x800 25 3s, 10.1ms\n",
            "image 34/100 /content/datasets/Car_detection-1/test/images/rain_storm-203_jpg.rf.acb9980617549fcddea1470ae8f6ce5d.jpg: 800x800 50 3s, 11.1ms\n",
            "image 35/100 /content/datasets/Car_detection-1/test/images/rain_storm-207_jpg.rf.5b3f22143ee32d10731689c643ed9dae.jpg: 800x800 1 3, 10.7ms\n",
            "image 36/100 /content/datasets/Car_detection-1/test/images/rain_storm-237_jpg.rf.f312bd4dd3f0a8c451bfd9bb754ead9b.jpg: 800x800 1 1, 9 3s, 3 8s, 10.2ms\n",
            "image 37/100 /content/datasets/Car_detection-1/test/images/rain_storm-395_jpg.rf.e49aba3a0c284c14e4ba27277cca1c65.jpg: 800x800 17 3s, 1 8, 10.6ms\n",
            "image 38/100 /content/datasets/Car_detection-1/test/images/rain_storm-419_jpg.rf.b2dd272b710d988ef440beba8a3ede0f.jpg: 800x800 10 3s, 10.0ms\n",
            "image 39/100 /content/datasets/Car_detection-1/test/images/rain_storm-427_jpg.rf.dcb16bedf7f1f8241874e583029e340a.jpg: 800x800 1 3, 10.0ms\n",
            "image 40/100 /content/datasets/Car_detection-1/test/images/rain_storm-447_jpg.rf.0accb9bceb8ce5e34cb4cb2cbed9abe8.jpg: 800x800 4 3s, 10.0ms\n",
            "image 41/100 /content/datasets/Car_detection-1/test/images/rain_storm-450_jpg.rf.7d992379394e1c0d3fbcdc08d0bc26c6.jpg: 800x800 4 3s, 12.7ms\n",
            "image 42/100 /content/datasets/Car_detection-1/test/images/rain_storm-466_jpg.rf.005688e7e9a490fbe9e86be2ae4ce6f3.jpg: 800x800 2 1s, 3 3s, 10.0ms\n",
            "image 43/100 /content/datasets/Car_detection-1/test/images/rain_storm-519_jpg.rf.79b68927011ac9d17d4039fb0ccaf42e.jpg: 800x800 13 3s, 1 6, 1 8, 10.0ms\n",
            "image 44/100 /content/datasets/Car_detection-1/test/images/rain_storm-650_jpg.rf.671f7cd214fffef4a1359021e063e632.jpg: 800x800 27 3s, 3 8s, 15.5ms\n",
            "image 45/100 /content/datasets/Car_detection-1/test/images/rain_storm-724_jpg.rf.871735a813a694c89a5d7ca0949cf8f1.jpg: 800x800 19 3s, 2 8s, 10.9ms\n",
            "image 46/100 /content/datasets/Car_detection-1/test/images/rain_storm-757_jpg.rf.f092076c11a59bae6847fe60bd360303.jpg: 800x800 19 3s, 11.1ms\n",
            "image 47/100 /content/datasets/Car_detection-1/test/images/rain_storm-775_jpg.rf.41865613263bfb8f6ba7fe7da7be8d2a.jpg: 800x800 16 3s, 11.8ms\n",
            "image 48/100 /content/datasets/Car_detection-1/test/images/rain_storm-807_jpg.rf.2a84b7e6e55ac6177cd5b807644960bc.jpg: 800x800 4 3s, 11.0ms\n",
            "image 49/100 /content/datasets/Car_detection-1/test/images/rain_storm-839_jpg.rf.9495918b3e0702c914e98fc147571761.jpg: 800x800 29 3s, 1 6, 11.9ms\n",
            "image 50/100 /content/datasets/Car_detection-1/test/images/rain_storm-855_jpg.rf.59ed52ed781eb5b20605360016c4b5a9.jpg: 800x800 34 3s, 5 8s, 11.3ms\n",
            "image 51/100 /content/datasets/Car_detection-1/test/images/sand_storm-027_jpg.rf.1aa8aea218b260f28a54e8dc1ed5aab5.jpg: 800x800 5 1s, 4 3s, 6 4s, 12.5ms\n",
            "image 52/100 /content/datasets/Car_detection-1/test/images/sand_storm-029_jpg.rf.3e47b35ea27b9a367b011f3faba92c3c.jpg: 800x800 1 3, 12.0ms\n",
            "image 53/100 /content/datasets/Car_detection-1/test/images/sand_storm-039_jpg.rf.3f95dac5b52b56f9c79f04918efb5999.jpg: 800x800 9 3s, 1 8, 10.0ms\n",
            "image 54/100 /content/datasets/Car_detection-1/test/images/sand_storm-048_jpg.rf.705d9f5a500ab6e16c840fffc6dd0984.jpg: 800x800 26 3s, 10.1ms\n",
            "image 55/100 /content/datasets/Car_detection-1/test/images/sand_storm-058_jpg.rf.c7f2faa839e66b183118af13cf1d74c9.jpg: 800x800 2 3s, 1 8, 10.0ms\n",
            "image 56/100 /content/datasets/Car_detection-1/test/images/sand_storm-116_jpg.rf.d97fa98ae057e440e63fc1df2822a0fa.jpg: 800x800 3 3s, 10.0ms\n",
            "image 57/100 /content/datasets/Car_detection-1/test/images/sand_storm-122_jpg.rf.31a8e3a38b40191f09945c797f9bdb77.jpg: 800x800 8 3s, 4 8s, 10.0ms\n",
            "image 58/100 /content/datasets/Car_detection-1/test/images/sand_storm-145_jpg.rf.e53d6972fa4efb4e07d7e7fb102b23b1.jpg: 800x800 3 3s, 1 8, 9.4ms\n",
            "image 59/100 /content/datasets/Car_detection-1/test/images/sand_storm-168_jpg.rf.140fcef29db4e2eafda9152c9abace4f.jpg: 800x800 1 1, 1 3, 9.4ms\n",
            "image 60/100 /content/datasets/Car_detection-1/test/images/sand_storm-213_jpg.rf.356f8a48def522a9d61c652be658dfab.jpg: 800x800 7 3s, 1 8, 11.3ms\n",
            "image 61/100 /content/datasets/Car_detection-1/test/images/sand_storm-214_jpg.rf.1f224d3ca795be325ede5b6c576c2a0f.jpg: 800x800 1 1, 22 3s, 1 6, 3 8s, 9.4ms\n",
            "image 62/100 /content/datasets/Car_detection-1/test/images/sand_storm-219_jpg.rf.173b6dd3dff63c65ccbef494d7ffd444.jpg: 800x800 13 3s, 9.4ms\n",
            "image 63/100 /content/datasets/Car_detection-1/test/images/sand_storm-236_jpg.rf.19468a1abaf1d45b67a30d8bad7f4af2.jpg: 800x800 5 3s, 1 8, 9.4ms\n",
            "image 64/100 /content/datasets/Car_detection-1/test/images/sand_storm-239_jpg.rf.e59bbf1c624d05e3bb5f1cc5b939aaf0.jpg: 800x800 97 3s, 1 8, 9.4ms\n",
            "image 65/100 /content/datasets/Car_detection-1/test/images/sand_storm-248_jpg.rf.c39e35aadad4549f9f0e47121e3ade8d.jpg: 800x800 6 3s, 9.4ms\n",
            "image 66/100 /content/datasets/Car_detection-1/test/images/sand_storm-292_jpg.rf.0b8f12277fb7358cc75f98aa2c762b63.jpg: 800x800 1 3, 9.4ms\n",
            "image 67/100 /content/datasets/Car_detection-1/test/images/sand_storm-297_jpg.rf.0caeb368b1463a173467faf9b14bfd77.jpg: 800x800 1 3, 1 8, 9.4ms\n",
            "image 68/100 /content/datasets/Car_detection-1/test/images/sand_storm-324_jpg.rf.932e6ec747b4a16c1ae44f038a680b80.jpg: 800x800 2 1s, 6 3s, 1 6, 1 8, 9.4ms\n",
            "image 69/100 /content/datasets/Car_detection-1/test/images/sand_storm-331_jpg.rf.15ea5fbe2bead78a0ae7629e54bb7c50.jpg: 800x800 4 3s, 3 6s, 1 8, 9.4ms\n",
            "image 70/100 /content/datasets/Car_detection-1/test/images/sand_storm-386_jpg.rf.65667bf679f7a9d37136e36003d57594.jpg: 800x800 3 3s, 9.4ms\n",
            "image 71/100 /content/datasets/Car_detection-1/test/images/sand_storm-391_jpg.rf.9af454911395db2892bc57a9b839fad7.jpg: 800x800 10 3s, 9.9ms\n",
            "image 72/100 /content/datasets/Car_detection-1/test/images/sand_storm-910_jpg.rf.c87e8f7625cc606bb78e68b586f52845.jpg: 800x800 4 3s, 12.1ms\n",
            "image 73/100 /content/datasets/Car_detection-1/test/images/sand_storm-911_jpg.rf.c72595e543bc4d2930a79225e183a28e.jpg: 800x800 4 3s, 9.4ms\n",
            "image 74/100 /content/datasets/Car_detection-1/test/images/sand_storm-936_jpg.rf.7cac96f74387a12a79aa5a5da6f9f7d6.jpg: 800x800 2 3s, 1 8, 9.4ms\n",
            "image 75/100 /content/datasets/Car_detection-1/test/images/sand_storm-978_jpg.rf.8043c9901f425f9d7e23cf314b552040.jpg: 800x800 4 3s, 9.4ms\n",
            "image 76/100 /content/datasets/Car_detection-1/test/images/sand_storm_g2_-001_jpg.rf.eecbe84349fb62cc8bc1387bf4f63221.jpg: 800x800 10 1s, 7 3s, 1 4, 1 8, 8.6ms\n",
            "image 77/100 /content/datasets/Car_detection-1/test/images/sand_storm_g2_-004_jpg.rf.79f86325103e9089978696899e97bf97.jpg: 800x800 6 1s, 8 3s, 8 4s, 9.1ms\n",
            "image 78/100 /content/datasets/Car_detection-1/test/images/sand_storm_g2_-006_jpg.rf.c78461d0047a39e93c7a7a79ad7897c1.jpg: 800x800 1 1, 6 3s, 7.9ms\n",
            "image 79/100 /content/datasets/Car_detection-1/test/images/sand_storm_g2_-009_jpg.rf.f6141a3d84bf7425518fe6e9e2997b1a.jpg: 800x800 29 3s, 2 6s, 6 8s, 7.8ms\n",
            "image 80/100 /content/datasets/Car_detection-1/test/images/sand_storm_g2_-015_jpg.rf.96f42eb5ef5e29d1740679ea6f31b931.jpg: 800x800 34 3s, 2 6s, 6 8s, 7.8ms\n",
            "image 81/100 /content/datasets/Car_detection-1/test/images/sand_storm_g2_-016_jpg.rf.a0c0e8a34a304a3655586a394782761d.jpg: 800x800 7 3s, 2 8s, 7.8ms\n",
            "image 82/100 /content/datasets/Car_detection-1/test/images/sand_storm_g2_-075_jpg.rf.f9902a5f0bcf46a46ecc2cf5652c32ad.jpg: 800x800 78 3s, 1 6, 1 8, 7.8ms\n",
            "image 83/100 /content/datasets/Car_detection-1/test/images/snow_storm-001_jpg.rf.1052bbc822771fb454d3f985500e11b4.jpg: 800x800 4 3s, 7.9ms\n",
            "image 84/100 /content/datasets/Car_detection-1/test/images/snow_storm-010_jpg.rf.7f53ae96f5ff30b85115e8746ded837d.jpg: 800x800 15 1s, 10 3s, 3 6s, 1 8, 7.8ms\n",
            "image 85/100 /content/datasets/Car_detection-1/test/images/snow_storm-016_jpg.rf.cd35a1e5880233c99493834aa268c555.jpg: 800x800 49 3s, 1 6, 6 8s, 7.8ms\n",
            "image 86/100 /content/datasets/Car_detection-1/test/images/snow_storm-029_jpg.rf.de63a9c07c5e9585cdd0b6718abf6790.jpg: 800x800 1 3, 7.9ms\n",
            "image 87/100 /content/datasets/Car_detection-1/test/images/snow_storm-060_jpg.rf.1206c5d5cce634ee0e21c12fb42ce3d2.jpg: 800x800 10 1s, 2 3s, 7.8ms\n",
            "image 88/100 /content/datasets/Car_detection-1/test/images/snow_storm-089_jpg.rf.846cb2434024087418bc098054d00c4f.jpg: 800x800 6 3s, 7.9ms\n",
            "image 89/100 /content/datasets/Car_detection-1/test/images/snow_storm-103_jpg.rf.72ae307c271f67e48effca6253f99e8d.jpg: 800x800 5 3s, 8.5ms\n",
            "image 90/100 /content/datasets/Car_detection-1/test/images/snow_storm-119_jpg.rf.d7d5f2e109adc929cdea1232965989f9.jpg: 800x800 44 3s, 2 6s, 2 8s, 8.0ms\n",
            "image 91/100 /content/datasets/Car_detection-1/test/images/snow_storm-149_jpg.rf.42e8bf3cd9ff62b88b5670080c22aedb.jpg: 800x800 5 1s, 4 3s, 7.9ms\n",
            "image 92/100 /content/datasets/Car_detection-1/test/images/snow_storm-243_jpg.rf.c9aefe3490c40410decd8a05936c3c67.jpg: 800x800 26 3s, 3 8s, 7.8ms\n",
            "image 93/100 /content/datasets/Car_detection-1/test/images/snow_storm-269_jpg.rf.196e7a045b1fd6b612b2cf591f327c27.jpg: 800x800 15 3s, 1 8, 7.9ms\n",
            "image 94/100 /content/datasets/Car_detection-1/test/images/snow_storm-271_jpg.rf.f0258be580e50efc9f9b28bbcb2f4c3e.jpg: 800x800 10 3s, 7.9ms\n",
            "image 95/100 /content/datasets/Car_detection-1/test/images/snow_storm-313_jpg.rf.0394e01af89db445a68f35dd149a07f2.jpg: 800x800 1 1, 12 3s, 1 4, 1 8, 7.8ms\n",
            "image 96/100 /content/datasets/Car_detection-1/test/images/snow_storm-317_jpg.rf.54cd8e8cd2617c9e262b7522c3d12726.jpg: 800x800 1 3, 7.8ms\n",
            "image 97/100 /content/datasets/Car_detection-1/test/images/snow_storm-339_jpg.rf.2841dbe91d2e7d39239562b86ff96af3.jpg: 800x800 2 3s, 7.8ms\n",
            "image 98/100 /content/datasets/Car_detection-1/test/images/snow_storm-354_jpg.rf.e75ee3d29bb038bc12f10200d77eb1c3.jpg: 800x800 17 3s, 7.9ms\n",
            "image 99/100 /content/datasets/Car_detection-1/test/images/snow_storm-362_jpg.rf.fd04fa674a772a5c5c79fcc68b364fd0.jpg: 800x800 73 3s, 1 8, 9.1ms\n",
            "image 100/100 /content/datasets/Car_detection-1/test/images/snow_storm-368_jpg.rf.f6642507ba0a96916df3f57b50b53d92.jpg: 800x800 6 3s, 7.9ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 11.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HFu3whThfur",
        "outputId": "d0c01181-a1f1-41df-e500-61832e02cfd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "LEcrn_jKhh0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = 'datasets'\n",
        "\n",
        "image_folder = os.path.join(HOME, datasets, 'runs', 'detect', 'predict')  # Folder containing the predicted images\n",
        "output_folder = os.path.join(HOME, 'runs', 'detect', 'videos')\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "dz7XDWXhhjXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
        "images.sort()\n"
      ],
      "metadata": {
        "id": "fbpIRj5uhlDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_groups = defaultdict(list)\n",
        "for img in images:\n",
        "    prefix = img.split('-')[0]\n",
        "    image_groups[prefix].append(img)\n"
      ],
      "metadata": {
        "id": "AFXkGEL7hnV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for condition, img_list in image_groups.items():\n",
        "    first_image_path = os.path.join(image_folder, img_list[0])\n",
        "    frame = cv2.imread(first_image_path)\n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    video_name = os.path.join(output_folder, f'{condition}_video.mp4')\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video = cv2.VideoWriter(video_name, fourcc, 0.25, (width, height))  # 0.25 fps for slow-motion effect\n",
        "\n",
        "    for image in img_list:\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        frame = cv2.imread(image_path)\n",
        "        video.write(frame)\n",
        "\n",
        "    video.release()\n",
        "\n",
        "    print(f\"Video created successfully for {condition} and saved as {video_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmqOStr6hqON",
        "outputId": "e5deac7f-cd5a-4330-f690-b46c37099dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video created successfully for dusttornado and saved as /content/runs/detect/videos/dusttornado_video.mp4\n",
            "Video created successfully for foggy and saved as /content/runs/detect/videos/foggy_video.mp4\n",
            "Video created successfully for haze and saved as /content/runs/detect/videos/haze_video.mp4\n",
            "Video created successfully for mist and saved as /content/runs/detect/videos/mist_video.mp4\n",
            "Video created successfully for rain_storm and saved as /content/runs/detect/videos/rain_storm_video.mp4\n",
            "Video created successfully for sand_storm and saved as /content/runs/detect/videos/sand_storm_video.mp4\n",
            "Video created successfully for sand_storm_g2_ and saved as /content/runs/detect/videos/sand_storm_g2__video.mp4\n",
            "Video created successfully for snow_storm and saved as /content/runs/detect/videos/snow_storm_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distance(bbox_width, real_width=1.8, focal_length=800):\n",
        "    \"\"\"\n",
        "    Calculate the distance from the camera to the object.\n",
        "\n",
        "    :param bbox_width: Width of the bounding box in pixels.\n",
        "    :param real_width: Real-world width of the object (car) in meters.\n",
        "    :param focal_length: Focal length of the camera.\n",
        "    :return: Distance to the object in meters.\n",
        "    \"\"\"\n",
        "    distance = (real_width * focal_length) / bbox_width\n",
        "    return distance\n"
      ],
      "metadata": {
        "id": "3HyxuejHhso8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def calculate_speed(previous_distance, current_distance, time_interval):\n",
        "    \"\"\"\n",
        "    Calculate the speed of the car.\n",
        "\n",
        "    :param previous_distance: Distance at the previous frame.\n",
        "    :param current_distance: Distance at the current frame.\n",
        "    :param time_interval: Time between frames.\n",
        "    :return: Speed in meters per second.\n",
        "    \"\"\"\n",
        "    distance_traveled = previous_distance - current_distance\n",
        "    speed = distance_traveled / time_interval\n",
        "    return speed\n"
      ],
      "metadata": {
        "id": "nAgB_pnnhsaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_time_to_hit(distance, speed):\n",
        "    \"\"\"\n",
        "    Calculate the time to hit the car.\n",
        "\n",
        "    :param distance: Current distance to the car.\n",
        "    :param speed: Speed of the car.\n",
        "    :return: Time to hit in seconds.\n",
        "    \"\"\"\n",
        "    if isinstance(speed, torch.Tensor):\n",
        "        speed = speed.mean().item()\n",
        "\n",
        "    if speed <= 0:\n",
        "        return float('inf')\n",
        "    time_to_hit = distance / speed\n",
        "    return time_to_hit\n"
      ],
      "metadata": {
        "id": "Gv8SXaO3hwcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "\n",
        "test_images_dir = '/content/datasets/Car_detection-1/test/images'\n",
        "\n",
        "test_images = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.png'))]\n",
        "\n",
        "model = YOLO('/content/datasets/runs/detect/train/weights/best.pt')\n",
        "\n",
        "previous_distance = None\n",
        "time_interval = 1 / 30  # Assuming 30 FPS\n",
        "\n",
        "for image_path in test_images:\n",
        "    start_time = time.time()\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    results = model.predict(image)\n",
        "\n",
        "    for result in results:\n",
        "        if result.boxes and len(result.boxes.xyxy) > 0:\n",
        "            for box in result.boxes.xyxy:\n",
        "                if box.shape[0] >= 4:\n",
        "                    bbox_width = box[2] - box[0]\n",
        "\n",
        "                    current_distance = calculate_distance(bbox_width)\n",
        "\n",
        "                    if previous_distance is not None:\n",
        "                        speed = calculate_speed(previous_distance, current_distance, time_interval)\n",
        "                        time_to_hit = calculate_time_to_hit(current_distance, speed)\n",
        "\n",
        "                    previous_distance = current_distance\n",
        "                else:\n",
        "                    print(f\"Bounding box with insufficient coordinates found in image: {image_path}\")\n",
        "        else:\n",
        "            print(f\"No valid bounding box found in image: {image_path}\")\n",
        "\n",
        "    time_interval = time.time() - start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkgWLO0ShyTa",
        "outputId": "48277416-bfe9-4c10-df74-85329e322ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 800x800 12 3s, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 12.7ms\n",
            "Speed: 3.3ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 52 3s, 1 8, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 14 3s, 2 8s, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 2 8s, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 6 1s, 6 3s, 1 6, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 11.3ms\n",
            "Speed: 5.0ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 10.0ms\n",
            "Speed: 3.8ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 1 6, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 9 3s, 1 8, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 5 3s, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 1s, 2 3s, 2 4s, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 6 3s, 9.2ms\n",
            "Speed: 3.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 7 3s, 1 8, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 16 3s, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 11 3s, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 1 8, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 12 3s, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 1 8, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 6 3s, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 7 3s, 1 8, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 1s, 2 3s, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 7 3s, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 (no detections), 9.0ms\n",
            "Speed: 2.6ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 800, 800)\n",
            "No valid bounding box found in image: /content/datasets/Car_detection-1/test/images/rain_storm-427_jpg.rf.dcb16bedf7f1f8241874e583029e340a.jpg\n",
            "\n",
            "0: 800x800 4 3s, 1 6, 9.1ms\n",
            "Speed: 2.8ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 19 3s, 3 8s, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 8 3s, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 7 3s, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 1s, 5 3s, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 15 3s, 8.9ms\n",
            "Speed: 3.6ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 14.9ms\n",
            "Speed: 3.5ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 5 3s, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 1s, 4 3s, 1 6, 2 8s, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 1s, 5 3s, 9.8ms\n",
            "Speed: 4.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 17 3s, 9.0ms\n",
            "Speed: 4.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 1 6, 2 8s, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 22 3s, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 20 3s, 2 6s, 1 8, 9.7ms\n",
            "Speed: 5.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 25 3s, 13.8ms\n",
            "Speed: 3.9ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 39 3s, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 9 3s, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 6 3s, 15.7ms\n",
            "Speed: 4.5ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 1 8, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 11.8ms\n",
            "Speed: 3.5ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 11 3s, 1 8, 9.4ms\n",
            "Speed: 4.6ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 28 3s, 4 8s, 10.2ms\n",
            "Speed: 4.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 1, 4 3s, 2 4s, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 5 1s, 4 3s, 1 8, 8.9ms\n",
            "Speed: 2.6ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 1s, 5 3s, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 17 3s, 1 6, 9.6ms\n",
            "Speed: 3.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 1, 7 3s, 2 8s, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 1 8, 10.8ms\n",
            "Speed: 2.9ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 (no detections), 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "No valid bounding box found in image: /content/datasets/Car_detection-1/test/images/haze-012_jpg.rf.5a5a05c0047c31012f6e50906a5d1831.jpg\n",
            "\n",
            "0: 800x800 3 3s, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 39 3s, 1 6, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 1s, 3 3s, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 11 3s, 2 6s, 2 8s, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 6 3s, 3 8s, 9.7ms\n",
            "Speed: 4.3ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 27 3s, 5 8s, 9.5ms\n",
            "Speed: 4.6ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 5 3s, 1 8, 9.6ms\n",
            "Speed: 4.9ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 2 3s, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 3.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 3s, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 16 3s, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 8 3s, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 1, 11 3s, 3 8s, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 6 3s, 1 8, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 13 3s, 9.4ms\n",
            "Speed: 3.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 14 3s, 2 8s, 13.3ms\n",
            "Speed: 3.5ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 26 3s, 1 6, 4 8s, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 5 3s, 10.0ms\n",
            "Speed: 4.1ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 3, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 9 3s, 12.9ms\n",
            "Speed: 3.4ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 3 1s, 6 3s, 2 4s, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 1 8, 11.1ms\n",
            "Speed: 7.0ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 1 8, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 5 1s, 1 3, 2 4s, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 800)\n",
            "\n",
            "0: 800x800 4 3s, 2 8s, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 800)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qoBJeTt3yD5b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}